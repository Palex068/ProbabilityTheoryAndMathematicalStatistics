# Разведочный анализ (EDA)
(exploratory data analysis)

Цель лекции:
+	познакомиться с основными понятиями выборки и генеральной совокупности
+	научиться рассчитывать и интерпретировать параметры описательной статистики
+	ознакомиться с принципами построения графиков
+	научиться читать графики, извлекать полезную информацию из них


Прошлое занятие было посвящено дискретным распределениям:
+ биномиальному и
+ распределению Пуассона. 

Закончили мы изучение этих распределений расчетами параметров описательной статистики. <br>
Сегодня изучим общие формулы для этих величин и будем их использовать далее, работая с нормальным распределением, которое является, наверное, самым важным распределением статистики. <br>
Но о нем речь пойдет на следующем занятии.

## Урок 3:
1.	[Понятия генеральной совокупности и выборки](#понятия-генеральной-совокупности-и-выборки)
2.	[Вероятность VS  Статистика](#вероятность-vs-статистика)
3.	[Математическое ожидание](#математическое-ожидание)
4.	[Дисперсия и среднее квадратичное отклонение](#дисперсия-и-среднее-квадратичное-отклонение)
5.	[Смещенное и несмещенное среднее квадратичное отклонение в Python](#смещенное-и-несмещенное-среднее-квадратичное-отклонение-в-python)
6.	[Медиана и мода](#медиана-и-мода)
7.	[Квартили, перцентили](#квартили-перцентили)
8.	[Размах](#размах)
9.	[Графический анализ](#графический-анализ)
10.	[Правила визуализации](#правила-визуализации)
11. [Статистики](#статистики)
12. [Решение задач](/S003.ipynb)
13. [Домашняя работа](/HW003.ipynb)

[Содержание курса](/README.MD)

##	Понятия генеральной совокупности и выборки

На прошлом уроке, при изучении дискретных распределений, мы уже затронули описательную статистику. Описательная статистика помогает нам узнать, как можно больше о случайной величине (далее СВ), которую мы изучаем.

С помощью математического ожидания мы можем узнать, вокруг какого значения группируется большая доля значений СВ, с помощью дисперсии оценить рассеянность данных вокруг среднего арифметического (математического ожидания). 

Мы познакомились со «специфическими» формулами для среднего арифметического и для дисперсии дискретных СВ. Сегодня посмотрим их в общем виде в рамках изучения темы разведочного анализа.

__Разведочный анализ__, основоположником которого является американский математик Джон Тьюки, является важной неотъемлемой частью всего статистического анализа. Это может быть достаточно большой пласт работы, которым не стоит пренебрегать. Потому что, в ходе разведочного анализа, вы можете обнаружить выбросы, которые, как мы помним, очень влияют на среднее арифметическое. Они также влияют на дисперсию. Мы можем обнаружить и другие интересные моменты, а также предварительно оценить результат, который мы хотим подтвердить тестированием гипотез, разведочный анализ  поможет выбрать правильные методы статистического анализа. 

Если не учесть все эти нюансы, то выводы, полученные при статистическом анализе, будут очень далеки от реального положения вещей. Более того, иногда разведочного анализа бывает достаточно, чтобы сделать выводы и не прибегать к каким-то дальнейшим вычислениям.

Разведочный анализ или _EDA_ от английского названия exploratory data analysis включает в себя описательную статистику и графический анализ. Начнем с первой его части, с описательной статистики, но для начала введем некоторые понятия

### Понятия
__Генеральная совокупность__ - это множество, которое содержит данные обо всех объектах, соответствующих определенным характеристикам.

Например, мы хотим измерить рост всех людей России. Если мы сможем измерить абсолютно каждого, то мы получим данные обо всей генеральной совокупности.<br> 
Но в реальной жизни обычно у нас нет доступа ко всей генеральной совокупности, поскольку:
+ во-первых,  измерить абсолютно всех людей России займет очень много времени,
+ во-вторых, это дорого, потому что нужно нанимать людей и платить, а,
+ в-третьих,  есть такие СВ, при измерении которых, нельзя вернуть объект обратно в генеральную совокупность. 

Например, краш-тест автомобиля.<br> 
Мы не можем перебить всю партию и отправить её на продажу. Та же история и с испытаниями на износ деталей. 

Когда мы измеряем всю генеральную совокупность, то мы проводим сплошной контроль. Но как вы видите, в реальной жизни это совсем невыгодно. Поэтому практически всегда мы прибегаем к выборочному контролю, т.е. берем репрезентативную (обычно «максимально» случайную) выборку.

__Выборка__ - это случайным образом выбранная часть генеральной   совокупности. 

По выборке мы можем получить точечные оценки истинных значений параметров генеральной совокупности. Т.е. чтобы узнать, например, среднее генеральной совокупности, мы должны измерить все ее объекты. Но т.к. обычно доступа у нас нет ко всем объектам по выше перечисленным причинам, то мы берем репрезентативную выборку необходимого объема  и измеряем  среднее по ней.<br> 
Это и будет точечная оценка истинного математического ожидания.

В зависимости от ситуации данные могут быть выборкой, а могут быть и генеральной совокупностью. 

Например, если мы хотим измерить рост всех людей на Земле и взяли людей из города $Х$, то люди, живущие в городе $Х$,  будут являться выборкой. 

Но, если мы хотим оценить рост людей, живущих в этом городе $Х$, и взяли случайных $100$ человек, то теперь все люди города $Х$ будут генеральной совокупностью.

[Содержание урока](#урок-3)

<hr>

##	Вероятность VS  Статистика

Чем же отличается теория вероятностей от статистики?

В теории вероятностей нам уже известна математическая модель.<br> 
И мы ее используем для того, чтобы предсказать, какой результат мы увидим.<br> 
Например, вероятность, что выпадет орел составляет ½, мы используем это значение, чтобы предсказать исход броска.

А в статистике мы не знаем поведения генеральной совокупности, которую мы изучаем. И набрав статистические данные, мы ищем закономерности, подбирая математическую модель, и затем эту модель экстраполируем на всю генеральную совокупность.<br>
Т.е. с помощью подобранной модели мы будем описывать поведение всей популяции.

![Вероятность VS  Статистика](/Pictures/003_001.png)

[Содержание урока](#урок-3)

<hr>

##	Математическое ожидание

Одной из самых важных характеристик описательной статистики является __математическое ожидание__,  которое находится, как среднее арифметическое всех элементов.<br> 

![математическое ожидание](/Pictures/003_031.PNG)

Для Генеральной совокупности:

Математическое ожидание — среднее значение случайной величины при стремлении количества выборок или количества измерений к бесконечности.<br>
Обозначается $M(X)$ и находиться по формуле:

$M(X)= \dfrac{1}{n} \cdot \displaystyle \sum_{i=1}^nx_i$, т.е. находится как среднее арифметическое.

Среднее арифметическое для выборки обозначается как $\bar {X}$

Находится по формуле 

$\bar X= \dfrac{1}{m} \cdot \displaystyle \sum_{i=1}^mx_i$, и называется 

Это точечная оценка точного математического ожидания - это среднее арифметическое одномерной случайной величины конечного числа испытаний обычно называют оценкой математического ожидания.

Иногда его еще называют «среднее». В реальной жизни мы обычно измеряем этот параметр по выборке.

Основная задача математического ожидания - показать, вокруг какого значения группируется большая доля значений случайной величины.

![Задача математического ожидания](/Pictures/003_016.PNG)

Недостатком среднего арифметического, напомню, является то, что оно очень чувствительно к выбросам, особенно при небольших объемах выборки.<br>
Пример:<br>
Заработные платы: $50, 52, 51, 50,  257$<br>
Получили среднее арифметическое $\underline{X}=92$<br>

![Задача математического ожидания](/Pictures/003_017.PNG)

А мы помним, что первоочередная задача математического ожидания - это описать, а  вокруг какого значения группируется большая доля значений СВ.<br> 

Но в данной ситуации математическое ожидание не справилось с этой задачей, потому что мы в маленькой выборке имеем выброс $(257)$. Получается, что $80\%$ значений выборки (4 из 5) лежат почти в $2$ раза ниже среднего арифметического.

В несимметричных распределениях можно пользоваться другой мерой центральной тенденции – __медианой__. О ней поговорим чуть позже.

[Содержание урока](#урок-3)

<hr>

##	Дисперсия и среднее квадратичное отклонение

Знакомясь с дискретными распределениями, мы уже давали определение дисперсии.

__Дисперсия__  характеризует степень рассеянности  значений случайной величины относительно ее математического ожидания. <br>
Обозначается $D(X)$ или $σ^2$<br>

Общая формула для нахождения дисперсии:

$σ^2=\dfrac{\sum _{i=1}^m \cdot (x_i  - \bar x)^2}{m}$, т.е. находим как среднее арифметическое


Эта формула для дисперсии генеральной совокупности, но опять же, в реальной жизни доступа ко всей генеральной совокупности у нас нет, поэтому и этот параметр мы оцениваем обычно по репрезентативной выборке.

Для выборки дисперсию обычно обозначают $S^2$, но иногда в книгах можно встретить и $σ^2$ для дисперсии по выборке.<br>
Понять, о  какой именно дисперсии идет речь можно по контексту.<br>
И работая с выборками, мы сталкиваемся с такими понятиями, как смещенная и несмещенная дисперсия.

Если объем выборки менее $100$, то обязательно используют формулу несмещенной дисперсии.

Сравним с формулой смещенной дисперсии

$S^2=\dfrac{\sum _{i=1}^n \cdot (x_i  - \bar x)^2}{n}$, где $n$ – объем выборки

Проще, просто всегда использовать формулу несмещенной дисперсии.<br>

__Дисперсия__ – квадратичная величина, поэтому пользоваться ей не очень удобно.<br> 

![Дисперсия](/Pictures/003_018.PNG)

![Дисперсия](/Pictures/003_032.PNG)

$n - 1$ - число степеней свободы

В статистике используют квадратный корень из дисперсии, стандартное отклонение.<br>
Его еще называют среднее квадратичное отклонение (𝞼 –для генеральной совокупности, $S$ – для выборки).

__Среднее квадратичное отклонение (далее СКО) показывает, насколько далеко наблюдения могут быть "разбросаны" относительно среднего значения.__

[Содержание урока](#урок-3)

<hr>

##	Смещенное и несмещенное среднее квадратичное отклонение в Python

![Дисперсия](/Pictures/003_019.PNG)

Для вычисления СКО используется функция $std()$.

$std$  расшифровывается как $standard\: deviation$, что в переводе означает стандартное отклонение.<br> 

Функция $var()$ используется для расчета дисперсии (на английском дисперсия – $variance$, отсюда и название функции).  

По умолчанию Python  рассчитывает смещенные параметры. Чтобы рассчитать несмещенные значения, в функции нужно прописать параметр $ddof=1$ (степени свободы).

Посчитаем смещенное стандартное отклонение и дисперсию для выборки $Х$

![среднее квадратичное отклонение в Python](/Pictures/003_002.png)

А теперь посчитаем несмещенное стандартное отклонение и дисперсию для выборки $Х$

![среднее квадратичное отклонение в Python](/Pictures/003_003.png)

[Содержание урока](#урок-3)

<hr>

##	Медиана и мода

Не всегда мы работаем с симметричными распределениями. <br>
Поэтому в качестве меры центральной тенденции иногда используют __медиану__. 

Она не чувствительна к выбросам и показывает, ниже какого значения лежат $50\%$ наблюдений, т.е.<br>
__медиана__ – это значение, которое делит выборку на две равные части так, что значения, которые меньше медианы, составляют $50\%$ выборки.

Чтобы посчитать медиану нужно сначала разместить значения по возрастанию.<br>
Медиана немного по-разному рассчитывается для четных и нечетных размеров выборки.

Возьмем нечетную выборку объемом $11$.<br> 
Сначала разместим значения по возрастанию. 
Ниже $6$-го элемента (число $2$) лежит $50\%$ наблюдений , т.е. $5$ значений и выше тоже $50\%$ наблюдений, $5$ значений.

![Медиана и мода](/Pictures/003_004.png)

Чтобы найти  этот $6$-й элемент мы воспользуемся формулой:

$N_{[(n+1)/2]}$,<br>   
где $n–$ объем выборки, а <br>
$N$ – элемент, соответствующий медиане.

$(11+1)/2=6$  - номер элемента, который является медианой в выборке нечетного размера.
Для четной выборки формула:

$\dfrac {N_{[\frac{n}{2}]}  + N_{[\frac{n}{2} + 1]}}{2}$,<br>
$n–$  четный объем выборки.<br> 
Медиана для ряда $1,3,7,8$ равна $5$

![Медиана и мода](/Pictures/003_005.png)

![Медиана и мода](/Pictures/003_020.PNG)

### Рассчитаем медиану в Python

![Медиана и мода](/Pictures/003_006.png)

### Мода

Еще одной мерой центральной тенденции является мода. 

![Медиана и мода](/Pictures/003_021.PNG)

Используется для категориальных данных.<br> 
Например, голосование за кандидатов Иванова, Петрова, Сидорова. Кто наберет большее число голосов, тот и будет модой.

[Содержание урока](#урок-3)

<hr>

##	Квартили, перцентили

Еще важные параметры, которые нам очень помогают в разведочном анализе, - это перцентили.

Если речь идет о каждом $25$-ом перцентиле, мы называем их __квартилями__, а о каждом $10$-ом, то __децентили__

Первый квартиль показывает значение, ниже которого лежат $25\%$ наблюдений.

Второй квартиль - это синоним медианы.

Третий квартиль показывает значение, ниже которого лежат $75\%$ наблюдений.

Т.е. сначала вам нужно отсортировать значения по возрастанию, а потом  вычислить, ниже какого значения лежат $25\%$ наблюдения или $50\%$, или $75\%$. 

Интерквартильное расстояние (еще его называют межквартильное ) - отрезок,  равный разности $3\%-го и $1$-го квартиля. 

### Параметры, нечувствительные к выбросам

![Параметры, нечувствительные к выбросам](/Pictures/003_022.PNG)

Есть формулы, которые позволяют рассчитать нам любой перцентиль.

Если $n*k/100$ –  целое число, тогда $k$-я перцентиль – это среднее значение элементов под номерами $n*k/100$ и $(n*k /100)+1$.

Здесь $n$ – объем выборки, <bt>
$k$ – перцентиль.

Если $n*k/100$ – нецелое число, то $k$-я перцентиль совпадает с измерением $j+1$, где $j$ –  максимальное целое число, которое меньше, чем $n*k/100$. 

Здесь $n$ – объем выборки, 
$k$ – перцентиль.

Посчитаем $1$ квартиль $(25\%)$ в Python. 

![Квартили, перцентили](/Pictures/003_007.png)

Поскольку нумерация в Python  с нуля, мы берем не $4$-й, а $3$-й индекс.

[Содержание урока](#урок-3)

<hr>

##	Размах

__Размах__ - очень чувствительный к выбросам параметр, т.к. это разность между максимальным и минимальным значением. Например, используется для построения гистограмм

![Размах](/Pictures/003_008.png)

[Содержание урока](#урок-3)

<hr>

##	Графический анализ

![Графическое представление данных](/Pictures/003_024.PNG)

Важной частью разведочного анализа (EDA) является графический анализ. 

С помощью графика мы можем взглянуть на данные целиком. 

График особенно ценен, когда он позволяет нам увидеть того, чего мы вообще не ожидали увидеть. 

Гистограмма и боксплот (еще его называют ящик с усами) являются самыми часто используемыми графиками, потому что они просты в построении и интерпретации результата и к тому же очень информативны

Гистограмма:

![Графический анализ](/Pictures/003_009.png)

Боксплот

![Боксплот](/Pictures/003_025.PNG)



![Графический анализ](/Pictures/003_010.png)

Давайте более подробно остановимся на ящиках с усами. 

Они бывают как с выбросами, так и без. <br>
Края усов в ящике без выбросов просто совпадают с максимальным и минимальным значением. <br>
Для ящика с выбросами края усов считаются по следующей формуле:<br>

$X_1= Q1 - 1.5*(Q3-Q1);$ 

$X_2 = Q3+ 1.5*(Q3-Q1)$

![Графический анализ](/Pictures/003_011.png)

$Q1$ – это $25$-й перцентиль
$Q3$ – это $75$-й перцентиль

Линия посередине соответствует медиане. 

Т.е. на нашем графике ниже, приблизительно,  $182$ см лежит $25\%$ значений, а приблизительно ниже $188$ лежит $75\%$ значений. <br>
Межквартильное расстояние $188-182 =6% см <br>
Т.е. $50\%$ значений попадают в диапазон между $182$ и $188$ см. <br>
Линия между $Q1$ и $Q3$ – это линия, соответствующая медиане.<br> 
Так мы можем приблизительно оценить по графику.<br>

Давайте попробуем интерпретировать информацию с этого __боксплота__.

![Графический анализ](/Pictures/003_012.png)

Здесь медиана совпадает с $1$-м квартилем, т.е. ниже, приблизительно, $120$ – ти лежат $50\%$ наблюдений и видим, что $1$ квартиль соответствует тем же $120$, т.е. ниже $120$ лежат $25\%$ наблюдений.

Что получается?<br> 
Что между $120$, которое соответствуют $1$-му квартилю и $120$, которое соответствуют медиане, лежит $25\%$ и они все будет равны $120$. 

Также видим большое количество выбросов - точки, расположенные за краями усов. <br> 
Распределение ассиметрично, медиана не проходит посередине  ящика.

[Содержание урока](#урок-3)

<hr>

##	Правила визуализации

При визуализации данных следует соблюдать некоторые правила, которые сделают ваш график «читабильным». <br>
Визуализируя данные, помните, что график должен сочетать в себе максимальную простоту и информативность.<br>

![Правила визуализации](/Pictures/003_023.PNG)

Вот правила, которые помогут вам добиться этого:
1.	Располагать значения в определенном порядке

![Правила визуализации](/Pictures/003_013.png)

2.	Избегать круговых диаграмм<br>
Нам проще сравнивать линейные величины, чем площади или объемы.
3.	Не использовать псевдотрехмерную графику (Не надо строить объемные барплоты)
4.	Стараться максимально просто изображать данные
5.	Использовать одинаковые единицы измерения
6.	Не оставлять много знаков после запятой
7.	Добавлять легенду на график

![Правила визуализации](/Pictures/003_014.png)

8.	При необходимости прибегать к масштабированию данных (например, применять log)

Когда полезно масштабирование данных?

Взглянем на данные.<br> 
На левом графике из-за 2 выбросов мы не видим, как изменяются (как рассеянны) остальные данные. <br>
Применив логарифмическое масштабирование данных, получаем боксплоты на правом графике, с которыми уже можно работать.

На следующем уроке мы будем знакомиться с непрерывной случайной величиной и с самым главным распределением статистики, с распределением Гаусса.

![Правила визуализации](/Pictures/003_015.png)

[Содержание урока](#урок-3)

<hr>

## Статистики

Для точечного оценивания параметров СВ используют различные статистики

Статистика – любая функция от выборки

Точечная оценка – наилучшее приближение к оцениваемому параметру

### 1. Среднее арифметическое / выборочное среднее

$\bar X= \dfrac{1}{m} \cdot \displaystyle \sum_{i=1}^mx_i$

Является оценкой для математического ожидания

### 2. Выборочная дисперсия (смещенная оценка) – оценивает 
дисперсию случайной величины

$σ^2=\dfrac{1}{m} \cdot \displaystyle\sum _{i=1}^m (x_i  - \bar x)^2$

оценка является несмещенной, если $M(Q*) = Q$, где $Q$ – это оцениваемый параметр

$σ^2=\dfrac{1}{n-1} \cdot \displaystyle\sum _{i=1}^n (x_i  - \bar X)^2$

Число степеней свободы – число независимых переменных за вычетом числа промежуточных оценок, используемых в процессе построение оценки

$\bar X=\dfrac{1}{n} \cdot \displaystyle\sum _{i=1}^n x_i$

$σ_X^2=\dfrac{1}{n-1} \cdot \displaystyle\sum _{i=1}^n (x_i  - \bar X)^2$

3. Среднеквадратическое отклонение (СКО)

$σ_X=\sqrt{\dfrac{1}{n-1} \cdot \displaystyle\sum _{i=1}^n (x_i  - \bar X)^2}$

4. Мода — наиболее часто встречающееся в выборке значение.

5. Медиана — такое значение $t$, что половина элементов из выборки 
меньше, либо равна $t$, и, соответственно, половина больше, либо 
равна $t$.

Представляет собой середину в отсортированной выборке

6. Квантиль
Квантиль порядка $α$ – такое число __𝑡𝛼__, что «α процентов» всех 
элементов выборки меньше __𝑡𝛼__, и соответственно, «(1 - α) 
процентов» элементов – больше __𝑡𝛼__

Медиана = квантиль порядка $0,5$
+ Первый квартиль – квантиль порядка $0.25$ (значение, которое не превышают $25\%$ элементов выборки)
+ Второй квартиль – квантиль порядка $0.5$
+ Третий квартиль – квантиль порядка $0.75$

__Дециль__ – квантиль порядка $0,1; 0,2$ и тд

__Перцентиль__ – аналог квантиля, но с использованием не доли, а процента (третий квартиль = 75% перцентиль)

__Интерквартильное расстояние__ / __размах__ — отрезок, равный разности третьей и первой квартили.

Отрезок, в который попадают 50% выборки

Используется для измерения разброса значений выборки вокруг среднего

__Квантиль случайной величины__

Квантилем порядка α случайной величины $X$ называют такое значение $t_a$, что 

$P(X \leq t_a) = a,\;P(X \geq t_a) = 1 - a$

В доле $α$ всех случаев значение случайной величины $Х$ окажется меньше $t_a$, и соответственно, в доле $(1 - α)$ случаев – больше $t_a$


[Содержание урока](#урок-3)

<hr>

## Решение задач Семинар 3 

### Задача 1

![Задача 1](/Pictures/003_026.PNG)

### Выводы
1. Преподаватели дотягивали до $65$ близкие ответы, для выдачи аттестатов
2. Людей сдавших тест хорошо, больше чем остальных - высокий уровень подготовки

### Задача 2

![Задача 2](/Pictures/003_027.PNG)

### Выводы

1. Проблема графиков в разной размерности графиков 

### Задача 3

![Задача 3](/Pictures/003_028.PNG)

### Выводы
1. Правый график более информативен:
  + есть легенда
  + есть цветовой акцент
2. Но оба графика не читабельны: 
  + в момент увеличения плотности значений
  + не учтен масштаб
  + нет читаемости названий штатов

### Задача 4

![Задача 4](/Pictures/003_029.PNG)

### Выводы

1. Наибольшая продолжительность жизни:
  + Европа
  + Азия
2. От $5$ до $8$ детей

### Задача 5

![Задача 5](/Pictures/003_030.PNG)

Среднее арифметическое:

$\bar X = \dfrac {\sum x_i}{n} $

$\dfrac{67 + 77 + 79 + 87 + 91 + 95 + 98 + 100 + 104 + 105}{10}=90.3$

Медиана

$Me = \dfrac {91+95}{2} = 93$

Интерквартильное расстояние

$IQR = Q3 - Q1$

Найдем $Q1$

$Q_1 =\dfrac{n\cdot k}{100} = \dfrac{10\cdot 25}{100}=2.5 \implies 2,$

т.к. результат не целое число, то округляем его в меньшую сторону $2$ и добавляем $1$, следовательно индекс равен $3$, а <br> 
$Q_1 =79$

$Q_3 =\dfrac{n\cdot k}{100} = \dfrac{10\cdot 75}{100}=7.5,$

т.к. результат не целое число, то округляем его в меньшую сторону $7$ и добавляем $1$, следовательно индекс равен $8$, а <br> 
$Q_3 =100$

$IQR = Q_3 - Q_1 = 100 - 79 = 21$

[Работа с python](/S003.ipynb)

[Содержание урока](#урок-3)

<hr>

[Содержание курса](/README.MD)